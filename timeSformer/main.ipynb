{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80802cbf",
   "metadata": {},
   "source": [
    "# Entrenamiento modelo timeSformer para LSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1defdd0",
   "metadata": {},
   "source": [
    "## Importar las dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115efdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, DefaultDataCollator, EarlyStoppingCallback\n",
    "from datasets import DatasetDict, load_from_disk \n",
    "\n",
    "import config\n",
    "# from train.optuna import objective\n",
    "from data.load import load_video_metadata, create_label_mappings\n",
    "from data.datasets import build_huggingface_dataset\n",
    "from data.preprocesing import create_map_function\n",
    "from model.load import load_model, load_image_processor\n",
    "from training.metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e25c0",
   "metadata": {},
   "source": [
    "## Verificar si se cuenta con tarjeta grafica compatible con CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee049c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fca6d",
   "metadata": {},
   "source": [
    "\n",
    "## PASO 1: Cargar Rutas y crear Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6771c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cargando Metadatos desde: ..\\dataset ---\n",
      "  Procesando: ..\\dataset\\train...\n",
      "    -> 150 videos cargados.\n",
      "  Procesando: ..\\dataset\\eval...\n",
      "    -> 30 videos cargados.\n",
      "  Procesando: ..\\dataset\\test...\n",
      "    -> 39 videos cargados.\n",
      "Metadatos cargados para 219 videos.\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta base\n",
    "base_dataset_path = Path(\"../dataset\")\n",
    "# Cargar datos de cada split\n",
    "# --- PASO 1: Cargar Metadatos ---\n",
    "base_dataset_path = Path(\"../dataset\")\n",
    "video_metadata = load_video_metadata(base_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5aad6",
   "metadata": {},
   "source": [
    "## PASO 2: Crear Mapeos y construir DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creando Mapeos de Etiquetas ---\n",
      "Se crearon mapeos para 10 clases.\n",
      "¡DatasetDict construido!\n",
      "\n",
      "--- Dataset Crudo Cargado ---\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['video_path', 'label'],\n",
      "        num_rows: 150\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['video_path', 'label'],\n",
      "        num_rows: 30\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['video_path', 'label'],\n",
      "        num_rows: 39\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "label2id, id2label = create_label_mappings(video_metadata)\n",
    "raw_dataset = build_huggingface_dataset(video_metadata, label2id)\n",
    "\n",
    "print(\"\\n--- Dataset Crudo Cargado ---\")\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d6c89",
   "metadata": {},
   "source": [
    "## PASO 3: Cargar Modelo e Image Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\n",
    "    model_ckpt=config.MODEL_CKPT,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    device=device,\n",
    "    freeze_base=True,\n",
    "    unfreeze_last_n=3\n",
    ")\n",
    "image_processor = load_image_processor(\n",
    "    model_ckpt=config.PROCCESSOR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6533a0aa",
   "metadata": {},
   "source": [
    "## PASO 4: Aplicando Preprocesamiento (PyAV + Aug Avanzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68039ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = width = image_processor.size[\"shortest_edge\"]\n",
    "resize_to = (height, width)\n",
    "num_frames_to_sample = model.config.num_frames\n",
    "\n",
    "processed_dataset_path = Path(\"./processed_sign_language_dataset\")\n",
    "\n",
    "if processed_dataset_path.exists():\n",
    "    print(f\"Cargando 'processed_dataset' desde el disco: {processed_dataset_path}\")\n",
    "    processed_dataset = load_from_disk(str(processed_dataset_path))\n",
    "    # Es importante volver a establecer el formato después de cargar desde disco\n",
    "    processed_dataset.set_format(\"torch\")\n",
    "    print(\"'processed_dataset' cargado.\")\n",
    "else:\n",
    "    train_map_fn = create_map_function(image_processor, num_frames_to_sample, resize_to, is_train=True)\n",
    "    val_test_map_fn = create_map_function(image_processor, num_frames_to_sample, resize_to, is_train=False)\n",
    "\n",
    "    # Aplicar .map() - ESTO ES LO QUE CREA EL CONTENIDO DEL NUEVO DATASET\n",
    "    processed_dataset = DatasetDict({\n",
    "        'train': raw_dataset['train'].map(train_map_fn, remove_columns=['video_path'], batched=False), # Quitamos path y label_str\n",
    "        'validation': raw_dataset['validation'].map(val_test_map_fn, remove_columns=['video_path'], batched=False),\n",
    "        'test': raw_dataset['test'].map(val_test_map_fn, remove_columns=['video_path'], batched=False),\n",
    "    })\n",
    "    \n",
    "    processed_dataset = processed_dataset.filter(\n",
    "        lambda x: x['pixel_values'] is not None\n",
    "    )\n",
    "    print(\"Filtrado completado.\")\n",
    "    processed_dataset.save_to_disk(str(processed_dataset_path))\n",
    "    # Establecer formato PyTorch\n",
    "    processed_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_video_frames(pixel_values, n=16, rows=4, cols=4):\n",
    "    n = min(n, len(pixel_values))\n",
    "    plt.figure(figsize=(cols*3, rows*3))\n",
    "    for i in range(n):\n",
    "        frame = pixel_values[i].permute(1, 2, 0).cpu().numpy()\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(frame)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Frame {i}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso:\n",
    "example = processed_dataset['train'][0]\n",
    "show_video_frames(example['pixel_values'], n=16, rows=4, cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4428d79",
   "metadata": {},
   "source": [
    "## PASO 5: Configurar el Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856de21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./results/timeSformer-LSC-finetuned\"\n",
    "learning_rate = 4.9610155578982295e-05 \n",
    "batch_size = 4\n",
    "num_epochs = 24 \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.013320764183634398,         \n",
    "    \n",
    "    # Estrategias de Evaluación y Guardado\n",
    "    eval_strategy=\"epoch\",    # Evaluar al final de cada época\n",
    "    save_strategy=\"epoch\",          # Guardar al final de cada época\n",
    "    load_best_model_at_end=True,    # Cargar el mejor modelo al final\n",
    "    save_total_limit=2,             # Guardar solo los 2 últimos/mejores checkpoints\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,         # Mejor si el F1 ponderado es mayor\n",
    "    # Logging y Otros\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,               # Cada cuántos pasos mostrar logs\n",
    "    remove_unused_columns=False,    # Importante si tu dataset tiene columnas extra\n",
    "    fp16=torch.cuda.is_available(), # Usar precisión mixta si hay GPU (acelera y ahorra VRAM)\n",
    "    # Early stopping\n",
    "    # Opcional: Para Optuna más adelante\n",
    "    # report_to=\"none\", # Podrías cambiarlo a 'wandb' o 'tensorboard'\n",
    ")\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,             \n",
    "    args=training_args,                \n",
    "    train_dataset=processed_dataset[\"train\"], \n",
    "    eval_dataset=processed_dataset[\"validation\"], \n",
    "    tokenizer=image_processor,         \n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,   \n",
    "    callbacks=[EarlyStoppingCallback(\n",
    "            early_stopping_patience=3,        # <-- aquí va la paciencia\n",
    "            early_stopping_threshold=0.0      # <-- aquí el delta mínimo de mejora\n",
    "        )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e891f5",
   "metadata": {},
   "source": [
    "## PASO 6: Iniciando Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Lanza el proceso de entrenamiento\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    print(\"\\n--- Entrenamiento Finalizado ---\")\n",
    "\n",
    "    # Guarda el mejor modelo encontrado durante el entrenamiento\n",
    "    print(\"Guardando el mejor modelo...\")\n",
    "    trainer.save_model()\n",
    "\n",
    "    # Guarda las métricas del entrenamiento\n",
    "    print(\"Guardando métricas de entrenamiento...\")\n",
    "    trainer.log_metrics(\"train\", train_results.metrics)\n",
    "    trainer.save_metrics(\"train\", train_results.metrics)\n",
    "\n",
    "    # Guarda el estado del Trainer (útil para reanudar)\n",
    "    trainer.save_state()\n",
    "    print(\"Métricas y estado del Trainer guardados.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcurrió un error durante el entrenamiento: {e}\")\n",
    "    print(\"Revisa los mensajes de error anteriores.\")\n",
    "    print(\"Posibles causas: Memoria VRAM/RAM insuficiente (reduce 'batch_size'),\")\n",
    "    print(\"problemas con los datos, configuración incorrecta o errores de CUDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb817b1",
   "metadata": {},
   "source": [
    "## PASO 7: Testear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a129aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimesformerForVideoClassification # El modelo que usas (ej: AutoModelForImageClassification)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = TimesformerForVideoClassification.from_pretrained(r\"results\\timeSformer-LSC-finetuned\",)\n",
    "\n",
    "# Prepara el Trainer solo para evaluación\n",
    "test_trainer = Trainer(\n",
    "    model=model,    \n",
    "    args=training_args,  # Puedes reusar los mismos argumentos, ajustando output_dir si quieres\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=processed_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "pred_output = test_trainer.predict(processed_dataset[\"test\"])\n",
    "y_true = pred_output.label_ids\n",
    "y_pred = pred_output.predictions.argmax(axis=1)  # Si es clasificación multiclase\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "class_names = [id2label[i] for i in range(len(id2label))]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.title(\"Matriz de confusión en el test set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1 (macro y weighted)\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision Macro:   {precision_macro:.4f}\")\n",
    "print(f\"Precision Weighted:{precision_weighted:.4f}\")\n",
    "print(f\"Recall Macro:      {recall_macro:.4f}\")\n",
    "print(f\"Recall Weighted:   {recall_weighted:.4f}\")\n",
    "print(f\"F1 Macro:          {f1_macro:.4f}\")\n",
    "print(f\"F1 Weighted:       {f1_weighted:.4f}\")\n",
    "\n",
    "# Classification report con nombres de clase\n",
    "target_names = [id2label[i] for i in range(len(id2label))]\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
